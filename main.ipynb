{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f1d695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R\\AppData\\Local\\Temp\\ipykernel_10672\\1419927350.py:78: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = LangChainOpenAI(temperature=0, openai_api_key=openai.api_key)\n",
      "C:\\Users\\R\\AppData\\Local\\Temp\\ipykernel_10672\\1419927350.py:80: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished. Transcribing...\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import OpenAI as LangChainOpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "import tempfile\n",
    "import pyttsx3  # Text-to-Speech library for speaking out the response\n",
    "\n",
    "# 1. Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 2. Text Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    text_chunks = text_splitter.split_text(text)\n",
    "    return text_chunks\n",
    "\n",
    "# 3. OpenFDA Search\n",
    "def search_openfda(medicine_name):\n",
    "    try:\n",
    "        url = f\"https://api.fda.gov/drug/label.json?search=openfda.brand_name:{medicine_name}&limit=1\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'results' in data:\n",
    "            result = data['results'][0]\n",
    "            brand_name = result['openfda'].get('brand_name', ['Unknown'])[0]\n",
    "            manufacturer = result['openfda'].get('manufacturer_name', ['Unknown'])[0]\n",
    "            usage = result.get('indications_and_usage', ['No usage information'])[0]\n",
    "            dosage = result.get('dosage_and_administration', ['No dosage information'])[0]\n",
    "            warnings = result.get('warnings', ['No warnings'])[0]\n",
    "            \n",
    "            return {\n",
    "                \"Brand Name\": brand_name,\n",
    "                \"Manufacturer\": manufacturer,\n",
    "                \"Usage\": usage,\n",
    "                \"Dosage\": dosage,\n",
    "                \"Warnings\": warnings\n",
    "            }\n",
    "        else:\n",
    "            return \"No information found in OpenFDA.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching from OpenFDA: {e}\"\n",
    "\n",
    "# 4. Chat with GPT\n",
    "def chat_with_gpt(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a medicine assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# 5. LangChain Tool for OpenFDA Search\n",
    "openfda_tool = Tool(\n",
    "    name=\"search_openfda\",\n",
    "    func=search_openfda,\n",
    "    description=\"Use this tool to get information about medicines from the OpenFDA database.\"\n",
    ")\n",
    "\n",
    "# 6. Setup Vector Database\n",
    "def setup_vector_db(texts):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_texts(texts, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "# 7. LangChain Agent\n",
    "llm = LangChainOpenAI(temperature=0, openai_api_key=openai.api_key)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[openfda_tool],\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 8. Speech Recognition using OpenAI Whisper API\n",
    "def recognize_speech_openai():\n",
    "    \"\"\"Record audio from mic and use OpenAI Whisper API.\"\"\"\n",
    "    fs = 16000  # Sample rate\n",
    "    seconds = 5  # Duration of recording\n",
    "    print(\"Recording...\")\n",
    "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording finished. Transcribing...\")\n",
    "\n",
    "    # Save recording temporarily\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "        wavfile.write(f.name, fs, (myrecording * 32767).astype(np.int16))\n",
    "        audio_file = open(f.name, \"rb\")\n",
    "        \n",
    "        # Send to OpenAI Whisper API for transcription\n",
    "        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "        return transcript[\"text\"]\n",
    "\n",
    "# 9. Text-to-Speech (TTS) using pyttsx3\n",
    "def speak_text(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# 10. GUI with Tkinter\n",
    "class MedicineAssistantApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Medicine Assistant\")\n",
    "        self.root.geometry(\"600x500\")\n",
    "        \n",
    "        frame = tk.Frame(self.root)\n",
    "        frame.pack(padx=10, pady=10, expand=True, fill=\"both\")\n",
    "        \n",
    "        self.conversation_display = scrolledtext.ScrolledText(frame, wrap=tk.WORD, width=70, height=20, font=(\"Arial\", 12))\n",
    "        self.conversation_display.pack(pady=5)\n",
    "        self.conversation_display.config(state=tk.DISABLED)\n",
    "        \n",
    "        self.user_input = tk.Entry(frame, width=70, font=(\"Arial\", 12))\n",
    "        self.user_input.pack(pady=5)\n",
    "        \n",
    "        self.send_button = tk.Button(frame, text=\"Send\", font=(\"Arial\", 12), command=self.handle_user_input)\n",
    "        self.send_button.pack(pady=5)\n",
    "\n",
    "        self.speech_button = tk.Button(frame, text=\"Speak\", font=(\"Arial\", 12), command=self.handle_speech_input)\n",
    "        self.speech_button.pack(pady=5)\n",
    "        \n",
    "    def display_message(self, message, is_user=False):\n",
    "        self.conversation_display.config(state=tk.NORMAL)\n",
    "        if is_user:\n",
    "            self.conversation_display.insert(tk.END, f\"You: {message}\\n\", \"user\")\n",
    "        else:\n",
    "            self.conversation_display.insert(tk.END, f\"Bot: {message}\\n\", \"bot\")\n",
    "        self.conversation_display.config(state=tk.DISABLED)\n",
    "        self.conversation_display.yview(tk.END)\n",
    "    \n",
    "    def handle_user_input(self):\n",
    "        user_query = self.user_input.get()\n",
    "        if user_query.lower() in [\"exit\", \"quit\"]:\n",
    "            self.root.quit()\n",
    "        \n",
    "        self.display_message(user_query, is_user=True)\n",
    "        \n",
    "        if \"what is\" in user_query.lower() or \"tell me about\" in user_query.lower():\n",
    "            medicine_name = user_query.lower().replace(\"what is\", \"\").replace(\"tell me about\", \"\").strip()\n",
    "            response = agent.run(medicine_name)\n",
    "            self.display_message(response)\n",
    "        else:\n",
    "            answer = chat_with_gpt(user_query)\n",
    "            self.display_message(answer)\n",
    "\n",
    "        self.user_input.delete(0, tk.END)\n",
    "        \n",
    "        # Speak the response\n",
    "        speak_text(answer)\n",
    "    \n",
    "    def handle_speech_input(self):\n",
    "        try:\n",
    "            speech_text = recognize_speech_openai()\n",
    "            self.display_message(speech_text, is_user=True)\n",
    "            \n",
    "            # Default answer if something goes wrong\n",
    "            answer = \"I'm sorry, I couldn't process that request.\"\n",
    "\n",
    "            if \"what is\" in speech_text.lower() or \"tell me about\" in speech_text.lower():\n",
    "                medicine_name = speech_text.lower().replace(\"what is\", \"\").replace(\"tell me about\", \"\").strip()\n",
    "                response = agent.run(medicine_name)\n",
    "                self.display_message(response)\n",
    "                answer = response  # Set the answer variable to the response\n",
    "            else:\n",
    "                answer = chat_with_gpt(speech_text)\n",
    "                self.display_message(answer)\n",
    "            \n",
    "            # Speak the response after generating the answer\n",
    "            speak_text(answer)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_message(f\"Speech recognition failed: {e}\")\n",
    "            answer = \"An error occurred while processing the speech input.\"\n",
    "            speak_text(answer)  # Speak the error message\n",
    "\n",
    "\n",
    "# 11. Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = MedicineAssistantApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
